{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5w5y06nA8dh"
      },
      "source": [
        "# Coding Task\n",
        "First, we need to set up the environment in Colab.\n",
        "\n",
        "### Installation & Imports Run this cell to install the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsD4zal2A_87",
        "outputId": "d1505af6-2f3b-4a78-e095-20d2b6f627a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (8.0.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.12/dist-packages (0.0.25)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: duckduckgo_search in /usr/local/lib/python3.12/dist-packages (8.1.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.11.12)\n",
            "Requirement already satisfied: orjson>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.11.4)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from pinecone) (3.0.1)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.1.0,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo_search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from duckduckgo_search) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.11)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install pinecone sentence-transformers flask flask-ngrok pytesseract opencv-python tensorflow duckduckgo_search\n",
        "!pip install flask pyngrok\n",
        "!pip install -q ddgs\n",
        "!sudo apt install tesseract-ocr\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import requests\n",
        "import json\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import threading\n",
        "from flask import Flask, render_template_string, request\n",
        "from pyngrok import ngrok\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from duckduckgo_search import DDGS\n",
        "from ddgs import DDGS\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Configuration\n",
        "PINECONE_API_KEY = \"YOUR_PINECONE_KEY_HERE\"\n",
        "INDEX_NAME = \"ecommerce-product-index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYaCAvw_B3Qy",
        "outputId": "e1fa4746-57ef-43c5-ed56-cce04a055ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial shape: (541909, 8)\n",
            "Cleaned shape: (535537, 8)\n"
          ]
        }
      ],
      "source": [
        "class DataCleaner:\n",
        "    def __init__(self, filepath):\n",
        "        self.filepath = \"/content/dataset.csv\"\n",
        "        self.df = None\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            self.df = pd.read_csv(self.filepath, encoding='ISO-8859-1')\n",
        "        except:\n",
        "            self.df = pd.read_csv(self.filepath, encoding='utf-8')\n",
        "        print(f\"Initial shape: {self.df.shape}\")\n",
        "\n",
        "    def clean(self):\n",
        "        # 1. Clean StockCode: Remove special chars like 'ö', '^', etc.\n",
        "        self.df['StockCode'] = self.df['StockCode'].astype(str).apply(lambda x: re.sub(r'[^A-Za-z0-9]', '', x))\n",
        "        self.df['StockCode'] = self.df['StockCode'].astype(str).apply(lambda x: re.sub(r'[^\\d]', '', x))\n",
        "\n",
        "        # 2. Clean Description: Remove '$', handle NaNs\n",
        "        self.df = self.df.dropna(subset=['Description'])\n",
        "        self.df['Description'] = self.df['Description'].astype(str).apply(lambda x: x.replace('$', '').strip())\n",
        "\n",
        "        # 3. Clean Quantity: Remove '@', convert to int\n",
        "        self.df['Quantity'] = self.df['Quantity'].astype(str).apply(lambda x: re.sub(r'[^\\d-]', '', x))\n",
        "        self.df['Quantity'] = pd.to_numeric(self.df['Quantity'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "        # 4. Clean UnitPrice\n",
        "        self.df['UnitPrice'] = self.df['UnitPrice'].astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
        "        self.df['UnitPrice'] = pd.to_numeric(self.df['UnitPrice'], errors='coerce').fillna(0.0)\n",
        "\n",
        "        # 5. Clean CustomerID: Remove '&', '#'\n",
        "        self.df['CustomerID'] = self.df['CustomerID'].astype(str).apply(lambda x: re.sub(r'[^\\d\\.]', '', x))\n",
        "\n",
        "        # 6. Clean Country: Remove 'XxY', '☺️'\n",
        "        self.df['Country'] = self.df['Country'].astype(str).apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x).replace('XxY', '').strip())\n",
        "\n",
        "        # 7. # Enforce strictly numbers in InvoiceNo\n",
        "        self.df['InvoiceNo'] = self.df['InvoiceNo'].astype(str).apply(lambda x: re.sub(r'[^\\d]', '', x))\n",
        "\n",
        "        # 8. Remove Duplicates\n",
        "        self.df = self.df.drop_duplicates()\n",
        "\n",
        "        # B. Drop rows containing ANY NaN values\n",
        "        self.df = self.df.dropna()\n",
        "\n",
        "        print(f\"Cleaned shape: {self.df.shape}\")\n",
        "        return self.df\n",
        "\n",
        "# Execute Cleaning\n",
        "cleaner = DataCleaner('dataset.csv')\n",
        "cleaner.load_data()\n",
        "df_clean = cleaner.clean()\n",
        "df_clean.to_csv('dataset_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "7U9lTJLhC60m",
        "outputId": "48b613a4-94d4-4134-a508-d9765abd6738"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       InvoiceNo StockCode                      Description  Quantity  \\\n",
              "541904    581587     22613      PACK OF 20 SPACEBOY NAPKINS        12   \n",
              "541905    581587     22899      CHILDREN'S APRON DOLLY GIRL         6   \n",
              "541906    581587     23254     CHILDRENS CUTLERY DOLLY GIRL         4   \n",
              "541907    581587     23255  CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
              "541908    581587     22138     BAKING SET 9 PIECE RETROSPOT         3   \n",
              "\n",
              "                InvoiceDate  UnitPrice CustomerID Country  \n",
              "541904  2011-12-09 12:50:00       0.85    12680.0  France  \n",
              "541905  2011-12-09 12:50:00       2.10    12680.0  France  \n",
              "541906  2011-12-09 12:50:00       4.15    12680.0  France  \n",
              "541907  2011-12-09 12:50:00       4.15    12680.0  France  \n",
              "541908  2011-12-09 12:50:00       4.95    12680.0  France  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64157b79-4b90-4295-8e37-86f6a9068a27\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>541904</th>\n",
              "      <td>581587</td>\n",
              "      <td>22613</td>\n",
              "      <td>PACK OF 20 SPACEBOY NAPKINS</td>\n",
              "      <td>12</td>\n",
              "      <td>2011-12-09 12:50:00</td>\n",
              "      <td>0.85</td>\n",
              "      <td>12680.0</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541905</th>\n",
              "      <td>581587</td>\n",
              "      <td>22899</td>\n",
              "      <td>CHILDREN'S APRON DOLLY GIRL</td>\n",
              "      <td>6</td>\n",
              "      <td>2011-12-09 12:50:00</td>\n",
              "      <td>2.10</td>\n",
              "      <td>12680.0</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541906</th>\n",
              "      <td>581587</td>\n",
              "      <td>23254</td>\n",
              "      <td>CHILDRENS CUTLERY DOLLY GIRL</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-12-09 12:50:00</td>\n",
              "      <td>4.15</td>\n",
              "      <td>12680.0</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541907</th>\n",
              "      <td>581587</td>\n",
              "      <td>23255</td>\n",
              "      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-12-09 12:50:00</td>\n",
              "      <td>4.15</td>\n",
              "      <td>12680.0</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541908</th>\n",
              "      <td>581587</td>\n",
              "      <td>22138</td>\n",
              "      <td>BAKING SET 9 PIECE RETROSPOT</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-12-09 12:50:00</td>\n",
              "      <td>4.95</td>\n",
              "      <td>12680.0</td>\n",
              "      <td>France</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64157b79-4b90-4295-8e37-86f6a9068a27')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64157b79-4b90-4295-8e37-86f6a9068a27 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64157b79-4b90-4295-8e37-86f6a9068a27');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c99b8962-91ba-40ba-ab8e-d2eae3a2b6dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c99b8962-91ba-40ba-ab8e-d2eae3a2b6dd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c99b8962-91ba-40ba-ab8e-d2eae3a2b6dd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_clean.tail(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4C4RjhFFOWJ"
      },
      "source": [
        "## Task 2 & 3: Vector Database & Similarity Metrics\n",
        "We use Cosine Similarity because it is the standard metric for semantic text similarity, measuring the angle between vectors rather than magnitude."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYBbDkr7FXNB"
      },
      "source": [
        "### Vector Database Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5_Wh215NDLk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae435a60-cb34-4592-d138-6383c760239d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class VectorDBManager:\n",
        "    def __init__(self, api_key, index_name):\n",
        "        self.pc = Pinecone(api_key=api_key)\n",
        "        self.index_name = index_name\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.index = None\n",
        "\n",
        "    def setup_index(self):\n",
        "        # (Same as your previous code)\n",
        "        existing_indexes = [i.name for i in self.pc.list_indexes()]\n",
        "        if self.index_name not in existing_indexes:\n",
        "            self.pc.create_index(\n",
        "                name=self.index_name,\n",
        "                dimension=384,\n",
        "                metric='cosine',\n",
        "                spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "            )\n",
        "        self.index = self.pc.Index(self.index_name)\n",
        "\n",
        "    def vectorize_and_upsert(self, df):\n",
        "        # (Same as your previous code...)\n",
        "        pass # Keep your existing logic here\n",
        "\n",
        "    def query_product(self, query_text, top_k=5):\n",
        "        query_vector = self.model.encode(query_text).tolist()\n",
        "        # ERROR FIX: You had 'tok_k' instead of 'top_k' below\n",
        "        result = self.index.query(vector=query_vector, top_k=top_k, include_metadata=True)\n",
        "        return result\n",
        "\n",
        "# Execute Vector Setup (Uncomment to run if you have a Key)\n",
        "vdb = VectorDBManager(PINECONE_API_KEY, INDEX_NAME)\n",
        "vdb.setup_index()\n",
        "vdb.vectorize_and_upsert(df_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA7_ulgTGABa"
      },
      "source": [
        "## Module 2: OCR and Web Scraping\n",
        "Task 4: OCR Implementation\n",
        "We use pytesseract to extract text from images.\n",
        "\n",
        "### OCR Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k1JTxqxiGFjy"
      },
      "outputs": [],
      "source": [
        "class OCRProcessor:\n",
        "    def __init__(self):\n",
        "        # Tesseract is already installed in the system\n",
        "        pass\n",
        "\n",
        "    def extract_text(self, image_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        # Preprocessing for better accuracy\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        text = pytesseract.image_to_string(gray)\n",
        "        return text.strip()\n",
        "\n",
        "# Test Usage\n",
        "ocr = OCRProcessor()\n",
        "text = ocr.extract_text('/content/WhatsApp Image 2025-02-20 at 01.47.25.jpeg.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMQ0gdezGZ3e"
      },
      "source": [
        "## Task 5: Web Scraping for CNN Data\n",
        "We need images for the classes in CNN_Model_Train_Data.csv. We will use duckduckgo_search to find images.\n",
        "\n",
        "### Image Scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPen5tBIGguf",
        "outputId": "b8d61e73-24c1-49b8-947a-38eb1d376d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for: LUNCH BAG PINK POLKADOT\n",
            "Downloaded 40 images for LUNCH BAG PINK POLKADOT\n",
            "Searching for: ALARM CLOCK BAKELIKE RED\n",
            "Downloaded 40 images for ALARM CLOCK BAKELIKE RED\n",
            "Searching for: CHOCOLATE HOT WATER BOTTLE\n",
            "Downloaded 40 images for CHOCOLATE HOT WATER BOTTLE\n",
            "Searching for: SPOTTY BUNTING\n",
            "Downloaded 40 images for SPOTTY BUNTING\n",
            "Searching for: LUNCH BAG WOODLAND\n",
            "Downloaded 39 images for LUNCH BAG WOODLAND\n",
            "Searching for: REX CASH+CARRY JUMBO SHOPPER\n",
            "Downloaded 39 images for REX CASH+CARRY JUMBO SHOPPER\n",
            "Searching for: JUMBO STORAGE BAG SUKI\n",
            "Downloaded 40 images for JUMBO STORAGE BAG SUKI\n",
            "Searching for: RETROSPOT TEA SET CERAMIC 11 PC\n",
            "Downloaded 40 images for RETROSPOT TEA SET CERAMIC 11 PC\n",
            "Searching for: 6 RIBBONS RUSTIC CHARM\n",
            "Downloaded 40 images for 6 RIBBONS RUSTIC CHARM\n",
            "Searching for: REGENCY CAKESTAND 3 TIER\n",
            "Downloaded 40 images for REGENCY CAKESTAND 3 TIER\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "class ImageScraper:\n",
        "    def __init__(self, save_dir='dataset_images'):\n",
        "        self.save_dir = save_dir\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "    def download_images(self, query, num_images=50):\n",
        "        print(f\"Searching for: {query}\")\n",
        "        folder_path = os.path.join(self.save_dir, query)\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        with DDGS() as ddgs:\n",
        "            results = list(ddgs.images(query, max_results=num_images))\n",
        "\n",
        "            count = 0\n",
        "            for res in results:\n",
        "                try:\n",
        "                    img_data = requests.get(res['image'], timeout=5).content\n",
        "                    with open(os.path.join(folder_path, f\"{count}.jpg\"), 'wb') as f:\n",
        "                        f.write(img_data)\n",
        "                    count += 1\n",
        "                    time.sleep(0.5) # Add a small delay to avoid rate limiting\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "        print(f\"Downloaded {count} images for {query}\")\n",
        "\n",
        "# Execute Scraping\n",
        "cnn_data = pd.read_csv('CNN_Model_Train_Data.csv')\n",
        "# Clean the stock codes here too using the same logic as before\n",
        "cnn_data['StockCode'] = cnn_data['StockCode'].astype(str).apply(lambda x: re.sub(r'[^A-Za-z0-9]', '', x))\n",
        "\n",
        "scraper = ImageScraper()\n",
        "\n",
        "# We need descriptions to search, let's map StockCodes to Descriptions from our clean dataset\n",
        "code_to_desc = df_clean.set_index('StockCode')['Description'].to_dict()\n",
        "\n",
        "for code in cnn_data['StockCode'].unique():\n",
        "    description = code_to_desc.get(code)\n",
        "    if description:\n",
        "        scraper.download_images(description, num_images=40) # 40 images per class for training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se7S5ZvsK1UF",
        "outputId": "a3b8d99c-dcf8-481b-9d3b-88e7a5c72d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning 'dataset_images' for corrupt images...\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/19.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/28.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/18.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/24.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/33.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/29.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/31.jpg\n",
            "Removing corrupt file: dataset_images/ALARM CLOCK BAKELIKE RED/20.jpg\n",
            "Removing corrupt file: dataset_images/RETROSPOT TEA SET CERAMIC 11 PC/22.jpg\n",
            "Removing corrupt file: dataset_images/RETROSPOT TEA SET CERAMIC 11 PC/10.jpg\n",
            "Removing corrupt file: dataset_images/REGENCY CAKESTAND 3 TIER/38.jpg\n",
            "Removing corrupt file: dataset_images/REGENCY CAKESTAND 3 TIER/33.jpg\n",
            "Removing corrupt file: dataset_images/REGENCY CAKESTAND 3 TIER/11.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/23.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/18.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/16.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/22.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/24.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/39.jpg\n",
            "Removing corrupt file: dataset_images/6 RIBBONS RUSTIC CHARM/21.jpg\n",
            "Removing corrupt file: dataset_images/LUNCH BAG PINK POLKADOT/3.jpg\n",
            "Removing corrupt file: dataset_images/LUNCH BAG PINK POLKADOT/10.jpg\n",
            "Removing corrupt file: dataset_images/CHOCOLATE HOT WATER BOTTLE/14.jpg\n",
            "Removing corrupt file: dataset_images/LUNCH BAG WOODLAND/28.jpg\n",
            "Cleanup complete. Removed 24 corrupt files.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def cleanup_corrupt_images(directory):\n",
        "    print(f\"Scanning '{directory}' for corrupt images...\")\n",
        "    deleted_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                # Try to open and verify the image\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify() # This checks if the file is broken without loading it fully\n",
        "            except (IOError, SyntaxError, Image.UnidentifiedImageError) as e:\n",
        "                # If it fails, print and delete the file\n",
        "                print(f\"Removing corrupt file: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                deleted_count += 1\n",
        "\n",
        "    print(f\"Cleanup complete. Removed {deleted_count} corrupt files.\")\n",
        "\n",
        "# RUN THIS before your training code\n",
        "cleanup_corrupt_images('dataset_images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XvD_FKeM9DZ"
      },
      "source": [
        "## Module 3: CNN Model Development\n",
        "Task 6: CNN Training\n",
        "We will build a simple CNN to classify products into the 10 classes found in CNN_Model_Train_Data.\n",
        "\n",
        "### CNN Model Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bQXjreeHD2E",
        "outputId": "e2b41bad-dbdc-4cd4-f381-8b54bf7c9e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 304 images belonging to 10 classes.\n",
            "Found 70 images belonging to 10 classes.\n",
            "Epoch 1/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.0951 - loss: 2.7909 - val_accuracy: 0.1143 - val_loss: 2.2964\n",
            "Epoch 2/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0944 - loss: 2.3152 - val_accuracy: 0.1000 - val_loss: 2.2806\n",
            "Epoch 3/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.1668 - loss: 2.2638 - val_accuracy: 0.1714 - val_loss: 2.2254\n",
            "Epoch 4/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.2624 - loss: 2.2111 - val_accuracy: 0.1714 - val_loss: 2.1662\n",
            "Epoch 5/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.2015 - loss: 2.1219 - val_accuracy: 0.3429 - val_loss: 2.0744\n",
            "Epoch 6/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.2834 - loss: 2.0891 - val_accuracy: 0.2714 - val_loss: 2.0372\n",
            "Epoch 7/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.3205 - loss: 2.0018 - val_accuracy: 0.3571 - val_loss: 1.9486\n",
            "Epoch 8/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.4505 - loss: 1.7847 - val_accuracy: 0.3714 - val_loss: 1.8728\n",
            "Epoch 9/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.4121 - loss: 1.8236 - val_accuracy: 0.4429 - val_loss: 1.9827\n",
            "Epoch 10/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.4536 - loss: 1.6981 - val_accuracy: 0.4429 - val_loss: 1.8124\n",
            "Epoch 11/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5070 - loss: 1.5306 - val_accuracy: 0.4571 - val_loss: 1.8535\n",
            "Epoch 12/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5177 - loss: 1.4703 - val_accuracy: 0.4714 - val_loss: 1.7935\n",
            "Epoch 13/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5006 - loss: 1.4780 - val_accuracy: 0.4000 - val_loss: 1.9131\n",
            "Epoch 14/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5704 - loss: 1.2966 - val_accuracy: 0.4714 - val_loss: 1.7459\n",
            "Epoch 15/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5669 - loss: 1.3095 - val_accuracy: 0.4571 - val_loss: 1.8544\n",
            "Epoch 16/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5702 - loss: 1.2406 - val_accuracy: 0.4143 - val_loss: 1.8969\n",
            "Epoch 17/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.6035 - loss: 1.1566 - val_accuracy: 0.5429 - val_loss: 1.7844\n",
            "Epoch 18/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5977 - loss: 1.1922 - val_accuracy: 0.4286 - val_loss: 1.8397\n",
            "Epoch 19/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.6674 - loss: 1.0592 - val_accuracy: 0.4286 - val_loss: 2.1750\n",
            "Epoch 20/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5780 - loss: 1.1225 - val_accuracy: 0.5000 - val_loss: 1.8852\n",
            "Epoch 21/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7080 - loss: 0.9726 - val_accuracy: 0.5429 - val_loss: 1.8613\n",
            "Epoch 22/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6892 - loss: 0.8608 - val_accuracy: 0.4857 - val_loss: 1.7495\n",
            "Epoch 23/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7471 - loss: 0.8080 - val_accuracy: 0.4571 - val_loss: 1.9933\n",
            "Epoch 24/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7030 - loss: 0.8241 - val_accuracy: 0.5000 - val_loss: 2.2138\n",
            "Epoch 25/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.7219 - loss: 0.7669 - val_accuracy: 0.5000 - val_loss: 2.0208\n",
            "Epoch 26/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7512 - loss: 0.7239 - val_accuracy: 0.5000 - val_loss: 2.1287\n",
            "Epoch 27/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.7718 - loss: 0.7456 - val_accuracy: 0.4714 - val_loss: 1.9097\n",
            "Epoch 28/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7778 - loss: 0.7321 - val_accuracy: 0.5571 - val_loss: 1.9170\n",
            "Epoch 29/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8138 - loss: 0.6075 - val_accuracy: 0.5714 - val_loss: 2.4295\n",
            "Epoch 30/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8147 - loss: 0.5999 - val_accuracy: 0.6143 - val_loss: 2.0143\n",
            "Epoch 31/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8096 - loss: 0.6326 - val_accuracy: 0.5143 - val_loss: 2.0799\n",
            "Epoch 32/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8212 - loss: 0.5394 - val_accuracy: 0.5143 - val_loss: 2.1860\n",
            "Epoch 33/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8306 - loss: 0.5492 - val_accuracy: 0.5714 - val_loss: 2.2300\n",
            "Epoch 34/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8493 - loss: 0.4714 - val_accuracy: 0.5857 - val_loss: 2.1828\n",
            "Epoch 35/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8481 - loss: 0.4860 - val_accuracy: 0.5429 - val_loss: 2.1218\n",
            "Epoch 36/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8225 - loss: 0.5316 - val_accuracy: 0.5429 - val_loss: 2.2483\n",
            "Epoch 37/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8556 - loss: 0.5178 - val_accuracy: 0.5286 - val_loss: 2.0195\n",
            "Epoch 38/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7782 - loss: 0.6299 - val_accuracy: 0.5429 - val_loss: 1.9037\n",
            "Epoch 39/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7816 - loss: 0.5551 - val_accuracy: 0.5286 - val_loss: 2.1739\n",
            "Epoch 40/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8508 - loss: 0.4170 - val_accuracy: 0.5143 - val_loss: 2.4798\n",
            "Epoch 41/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8505 - loss: 0.4516 - val_accuracy: 0.5286 - val_loss: 2.2098\n",
            "Epoch 42/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8806 - loss: 0.4272 - val_accuracy: 0.5286 - val_loss: 2.1719\n",
            "Epoch 43/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8479 - loss: 0.4518 - val_accuracy: 0.5714 - val_loss: 1.9465\n",
            "Epoch 44/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8917 - loss: 0.3768 - val_accuracy: 0.5429 - val_loss: 2.1742\n",
            "Epoch 45/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8843 - loss: 0.3730 - val_accuracy: 0.5143 - val_loss: 2.4958\n",
            "Epoch 46/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8864 - loss: 0.3424 - val_accuracy: 0.5286 - val_loss: 2.2078\n",
            "Epoch 47/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9349 - loss: 0.2445 - val_accuracy: 0.5571 - val_loss: 2.1509\n",
            "Epoch 48/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2684 - val_accuracy: 0.5143 - val_loss: 2.3798\n",
            "Epoch 49/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8866 - loss: 0.2953 - val_accuracy: 0.5857 - val_loss: 2.5027\n",
            "Epoch 50/50\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9097 - loss: 0.2849 - val_accuracy: 0.5571 - val_loss: 2.9413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as product_cnn_model.h5\n"
          ]
        }
      ],
      "source": [
        "class CNNModelTrainer:\n",
        "    def __init__(self, data_dir='dataset_images'):\n",
        "        self.data_dir = data_dir\n",
        "        self.img_height = 128\n",
        "        self.img_width = 128\n",
        "        self.batch_size = 32\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Use ImageDataGenerator for augmentation and loading\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            validation_split=0.2,\n",
        "            rotation_range=20,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "\n",
        "        self.train_generator = train_datagen.flow_from_directory(\n",
        "            self.data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='training'\n",
        "        )\n",
        "\n",
        "        self.validation_generator = train_datagen.flow_from_directory(\n",
        "            self.data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='categorical',\n",
        "            subset='validation'\n",
        "        )\n",
        "        self.class_names = list(self.train_generator.class_indices.keys())\n",
        "\n",
        "    def build_model(self):\n",
        "        num_classes = len(self.class_names)\n",
        "        self.model = Sequential([\n",
        "            Conv2D(32, (3, 3), activation='relu', input_shape=(self.img_height, self.img_width, 3)),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Conv2D(64, (3, 3), activation='relu'),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Conv2D(128, (3, 3), activation='relu'),\n",
        "            MaxPooling2D(2, 2),\n",
        "            Flatten(),\n",
        "            Dense(512, activation='relu'),\n",
        "            Dropout(0.5),\n",
        "            Dense(num_classes, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        self.model.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "    def train(self, epochs=50):\n",
        "        self.model.fit(\n",
        "            self.train_generator,\n",
        "            validation_data=self.validation_generator,\n",
        "            epochs=epochs\n",
        "        )\n",
        "        self.model.save('product_cnn_model.h5')\n",
        "        print(\"Model saved as product_cnn_model.h5\")\n",
        "\n",
        "# Execute Training (Only if images are downloaded)\n",
        "trainer = CNNModelTrainer()\n",
        "trainer.prepare_data()\n",
        "trainer.build_model()\n",
        "trainer.train(epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGbw95c8Nskr"
      },
      "source": [
        "## Module 4: Frontend Development and Integration\n",
        "Flask Application\n",
        "This handles all endpoints (/, /query, /upload_query, /detect_product).\n",
        "\n",
        "### Flask App"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from flask import Flask, request, render_template_string\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- 1. DEFINE HELPER FUNCTIONS (RETURNING STRUCTURED DATA) ---\n",
        "\n",
        "def recommend_products(query_text):\n",
        "    \"\"\"Searches Pinecone, looks up details in df_clean, and returns structured data.\"\"\"\n",
        "    if not query_text:\n",
        "        return \"No query provided.\", []\n",
        "\n",
        "    try:\n",
        "        # Query Pinecone\n",
        "        results = vdb.query_product(query_text, top_k=5)\n",
        "    except NameError:\n",
        "        return \"Error: Database (vdb) not loaded.\", []\n",
        "    except Exception as e:\n",
        "        return f\"Error querying database: {str(e)}\", []\n",
        "\n",
        "    recommendations = []\n",
        "\n",
        "    # Handle Pinecone Response Object (v2 vs v3 compatibility)\n",
        "    matches = []\n",
        "    if hasattr(results, 'matches'):\n",
        "        matches = results.matches\n",
        "    elif isinstance(results, dict) and 'matches' in results:\n",
        "        matches = results['matches']\n",
        "\n",
        "    for match in matches:\n",
        "        # 1. Get Metadata from Pinecone match\n",
        "        if isinstance(match, dict):\n",
        "            metadata = match.get('metadata', {})\n",
        "            score = match.get('score', 0)\n",
        "        else:\n",
        "            metadata = getattr(match, 'metadata', {})\n",
        "            score = getattr(match, 'score', 0)\n",
        "\n",
        "        # 2. Extract Description\n",
        "        description = \"Unknown Product\"\n",
        "        if isinstance(metadata, dict):\n",
        "            description = metadata.get('description', 'Unknown Product')\n",
        "        elif hasattr(metadata, 'get'):\n",
        "             description = metadata.get('description', 'Unknown Product')\n",
        "\n",
        "        # 3. Look up Price and StockCode from the global df_clean DataFrame\n",
        "        # We filter the dataframe to find the matching description to get the price\n",
        "        price = \"N/A\"\n",
        "        stock_code = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            # Find the row in the clean dataframe that matches this description\n",
        "            product_row = df_clean[df_clean['Description'] == description]\n",
        "            if not product_row.empty:\n",
        "                # Take the first match\n",
        "                price = product_row.iloc[0]['UnitPrice']\n",
        "                stock_code = product_row.iloc[0]['StockCode']\n",
        "        except Exception:\n",
        "            pass # Keep defaults if lookup fails\n",
        "\n",
        "        # 4. Append structured dictionary instead of a string\n",
        "        recommendations.append({\n",
        "            'description': description,\n",
        "            'price': price,\n",
        "            'stock_code': stock_code,\n",
        "            'score': round(score, 2)\n",
        "        })\n",
        "\n",
        "    response_text = f\"Found {len(recommendations)} matches for '{query_text}'.\"\n",
        "    return response_text, recommendations\n",
        "\n",
        "def process_ocr_query(image_path):\n",
        "    \"\"\"Extracts text from image, then searches Pinecone.\"\"\"\n",
        "    try:\n",
        "        extracted_text = ocr.extract_text(image_path)\n",
        "    except NameError:\n",
        "        return \"Error: OCR processor not loaded.\", [], \"\"\n",
        "\n",
        "    if not extracted_text:\n",
        "        return \"No text detected in image.\", [], \"\"\n",
        "\n",
        "    # Use the text we found to search products\n",
        "    response_text, recommendations = recommend_products(extracted_text)\n",
        "    return response_text, recommendations, extracted_text\n",
        "\n",
        "def predict_product_from_image(image_path):\n",
        "    \"\"\"Uses CNN to classify image, then searches Pinecone for that class.\"\"\"\n",
        "    try:\n",
        "        # Load and preprocess image for the model (128x128)\n",
        "        img = keras_image.load_img(image_path, target_size=(128, 128))\n",
        "        img_array = keras_image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array /= 255.0\n",
        "\n",
        "        # Predict using your trainer model\n",
        "        predictions = trainer.model.predict(img_array)\n",
        "        class_idx = np.argmax(predictions[0])\n",
        "        predicted_class = trainer.class_names[class_idx]\n",
        "\n",
        "        # Search for products matching the predicted class\n",
        "        response_text, recommendations = recommend_products(predicted_class)\n",
        "\n",
        "        return predicted_class, response_text, recommendations\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", \"Could not process image\", []\n",
        "\n",
        "# --- 2. RESET THE FLASK APP ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Ngrok Setup\n",
        "# Note: Ensure your Authtoken is valid.\n",
        "NGROK_AUTH_TOKEN = \"YOUR_PINECONE_KEY_HERE\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "# Kill previous tunnels to avoid conflicts\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\" * Public URL: {public_url}\")\n",
        "\n",
        "# --- 3. UPDATED HTML TEMPLATE (WITH TABLE) ---\n",
        "html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>AI E-commerce Assistant</title>\n",
        "    <style>\n",
        "        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; padding: 20px; background-color: #f4f4f9; }\n",
        "        .container { max-width: 900px; margin: auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }\n",
        "        h1 { color: #333; text-align: center; }\n",
        "        nav { text-align: center; margin-bottom: 20px; }\n",
        "        nav a { margin: 0 15px; text-decoration: none; color: #007bff; font-weight: bold; font-size: 1.1em; }\n",
        "        nav a:hover { text-decoration: underline; }\n",
        "        .result { background: #e9ecef; padding: 20px; margin-top: 20px; border-radius: 8px; }\n",
        "\n",
        "        /* Table Styles */\n",
        "        table { width: 100%; border-collapse: collapse; margin-top: 15px; background: white; }\n",
        "        th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }\n",
        "        th { background-color: #007bff; color: white; }\n",
        "        tr:hover { background-color: #f1f1f1; }\n",
        "\n",
        "        form { margin-top: 20px; text-align: center; }\n",
        "        input[type=\"text\"] { padding: 10px; width: 60%; border: 1px solid #ddd; border-radius: 4px; }\n",
        "        button { padding: 10px 20px; background-color: #28a745; color: white; border: none; border-radius: 4px; cursor: pointer; }\n",
        "        button:hover { background-color: #218838; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"container\">\n",
        "    <h1>AI Product Assistant</h1>\n",
        "    <nav>\n",
        "        <a href=\"/\">Text Search</a> |\n",
        "        <a href=\"/ocr\">Handwritten Search</a> |\n",
        "        <a href=\"/vision\">Image Detection</a>\n",
        "    </nav>\n",
        "    <hr>\n",
        "\n",
        "    {% if page == 'text' %}\n",
        "    <h2 style=\"text-align:center;\">Find Products by Description</h2>\n",
        "    <form method=\"post\">\n",
        "        <input type=\"text\" name=\"query\" placeholder=\"E.g., 'White metal lantern'...\" required>\n",
        "        <button type=\"submit\">Search</button>\n",
        "    </form>\n",
        "    {% elif page == 'ocr' %}\n",
        "    <h2 style=\"text-align:center;\">Upload Handwritten Note</h2>\n",
        "    <form method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" required>\n",
        "        <button type=\"submit\">Upload & Read</button>\n",
        "    </form>\n",
        "    {% elif page == 'vision' %}\n",
        "    <h2 style=\"text-align:center;\">Upload Product Image</h2>\n",
        "    <form method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" required>\n",
        "        <button type=\"submit\">Identify Product</button>\n",
        "    </form>\n",
        "    {% endif %}\n",
        "\n",
        "    {% if result %}\n",
        "    <div class=\"result\">\n",
        "        <h3>Analysis Results:</h3>\n",
        "        <p><strong>System Response:</strong> {{ response_text }}</p>\n",
        "        {% if extracted %} <p><strong>Extracted Text:</strong> <em>\"{{ extracted }}\"</em></p> {% endif %}\n",
        "        {% if predicted_class %} <p><strong>Detected Category:</strong> <span style=\"color:green; font-weight:bold;\">{{ predicted_class }}</span></p> {% endif %}\n",
        "\n",
        "        <h4>Recommended Products:</h4>\n",
        "        {% if recommendations %}\n",
        "        <table>\n",
        "            <thead>\n",
        "                <tr>\n",
        "                    <th style=\"width: 50%;\">Product Name</th>\n",
        "                    <th>Stock Code</th>\n",
        "                    <th>Price ($)</th>\n",
        "                    <th>Relevance Score</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                {% for item in recommendations %}\n",
        "                <tr>\n",
        "                    <td>{{ item.description }}</td>\n",
        "                    <td>{{ item.stock_code }}</td>\n",
        "                    <td>{{ item.price }}</td>\n",
        "                    <td>{{ item.score }}</td>\n",
        "                </tr>\n",
        "                {% endfor %}\n",
        "            </tbody>\n",
        "        </table>\n",
        "        {% else %}\n",
        "        <p>No products found matching your query.</p>\n",
        "        {% endif %}\n",
        "        </div>\n",
        "    {% endif %}\n",
        "</div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. ROUTES ---\n",
        "@app.route('/', methods=['GET', 'POST'])\n",
        "def text_query():\n",
        "    result = None\n",
        "    response_text = \"\"\n",
        "    recommendations = []\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        query = request.form.get('query', '')\n",
        "        response_text, recommendations = recommend_products(query)\n",
        "        result = True\n",
        "\n",
        "    return render_template_string(html_template, page='text', result=result, response_text=response_text, recommendations=recommendations)\n",
        "\n",
        "@app.route('/ocr', methods=['GET', 'POST'])\n",
        "def ocr_query():\n",
        "    result = None\n",
        "    response_text = \"\"\n",
        "    recommendations = []\n",
        "    extracted = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return \"No file uploaded\"\n",
        "        file = request.files['file']\n",
        "        if file.filename != '':\n",
        "            filepath = os.path.join('static', file.filename)\n",
        "            os.makedirs('static', exist_ok=True)\n",
        "            file.save(filepath)\n",
        "\n",
        "            response_text, recommendations, extracted = process_ocr_query(filepath)\n",
        "            result = True\n",
        "\n",
        "    return render_template_string(html_template, page='ocr', result=result, response_text=response_text, recommendations=recommendations, extracted=extracted)\n",
        "\n",
        "@app.route('/vision', methods=['GET', 'POST'])\n",
        "def vision_query():\n",
        "    result = None\n",
        "    response_text = \"\"\n",
        "    recommendations = []\n",
        "    predicted_class = \"\"\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return \"No file uploaded\"\n",
        "        file = request.files['file']\n",
        "        if file.filename != '':\n",
        "            filepath = os.path.join('static', file.filename)\n",
        "            os.makedirs('static', exist_ok=True)\n",
        "            file.save(filepath)\n",
        "\n",
        "            predicted_class, response_text, recommendations = predict_product_from_image(filepath)\n",
        "            result = True\n",
        "\n",
        "    return render_template_string(html_template, page='vision', result=result, response_text=response_text, recommendations=recommendations, predicted_class=predicted_class)\n",
        "\n",
        "# --- 5. RUN ---\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYXBFdo57ReW",
        "outputId": "991a620d-44ee-412e-9f0e-503c2e464afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Public URL: https://fitful-anapaestically-jarvis.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Dec/2025 17:23:28] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Dec/2025 17:23:35] \"GET /vision HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [05/Dec/2025 17:23:57] \"POST /vision HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Dec/2025 17:45:53] \"GET / HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}